{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 678013 entries, 0 to 678012\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   IDpol       678013 non-null  float64\n",
      " 1   ClaimNb     678013 non-null  float64\n",
      " 2   Exposure    678013 non-null  float64\n",
      " 3   Area        678013 non-null  object \n",
      " 4   VehPower    678013 non-null  float64\n",
      " 5   VehAge      678013 non-null  float64\n",
      " 6   DrivAge     678013 non-null  float64\n",
      " 7   BonusMalus  678013 non-null  float64\n",
      " 8   VehBrand    678013 non-null  object \n",
      " 9   VehGas      678013 non-null  object \n",
      " 10  Density     678013 non-null  float64\n",
      " 11  Region      678013 non-null  object \n",
      "dtypes: float64(8), object(4)\n",
      "memory usage: 62.1+ MB\n",
      "Empty DataFrame\n",
      "Columns: [IDpol, ClaimNb, Exposure, Area, VehPower, VehAge, DrivAge, BonusMalus, VehBrand, VehGas, Density, Region]\n",
      "Index: []\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26639 entries, 0 to 26638\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   IDpol        26639 non-null  float64\n",
      " 1   PurePremium  26639 non-null  float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 416.4 KB\n",
      "        IDpol  PurePremium\n",
      "0      1552.0       995.20\n",
      "7   4020812.0     54942.62\n",
      "8   4020812.0      7620.00\n",
      "22  4002743.0       556.14\n",
      "23  4002743.0      1204.00\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3068 entries, 0 to 26636\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   IDpol        3068 non-null   float64\n",
      " 1   PurePremium  3068 non-null   float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 71.9 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "\n",
    "import arff\n",
    "data_freq = arff.load('freMTPL2freq.arff') \n",
    "df_freq = pd.DataFrame(data_freq, columns=[\"IDpol\", \"ClaimNb\", \"Exposure\", \"Area\", \"VehPower\", \"VehAge\",\"DrivAge\", \"BonusMalus\", \"VehBrand\", \"VehGas\", \"Density\", \"Region\"])\n",
    "df_freq.head()\n",
    "df_freq.info()\n",
    "df_freq.describe()\n",
    "\n",
    "duplicates = df_freq[df_freq.duplicated(subset=['IDpol'], keep=False)]\n",
    "print(duplicates.head())\n",
    "\n",
    "data_sev = arff.load('freMTPL2sev.arff') \n",
    "df_sev = pd.DataFrame(data_sev, columns=[\"IDpol\", \"PurePremium\"])\n",
    "df_sev.head()\n",
    "df_sev.info()\n",
    "df_sev.describe()\n",
    "\n",
    "\n",
    "duplicates = df_sev[df_sev.duplicated(subset=['IDpol'], keep=False)]\n",
    "print(duplicates.head())\n",
    "duplicates.info()\n",
    "## I see 3068 rows of duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24944 entries, 0 to 24943\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   IDpol        24944 non-null  float64\n",
      " 1   ClaimNb      24944 non-null  float64\n",
      " 2   Exposure     24944 non-null  float64\n",
      " 3   Area         24944 non-null  object \n",
      " 4   VehPower     24944 non-null  float64\n",
      " 5   VehAge       24944 non-null  float64\n",
      " 6   DrivAge      24944 non-null  float64\n",
      " 7   BonusMalus   24944 non-null  float64\n",
      " 8   VehBrand     24944 non-null  object \n",
      " 9   VehGas       24944 non-null  object \n",
      " 10  Density      24944 non-null  float64\n",
      " 11  Region       24944 non-null  object \n",
      " 12  PurePremium  24944 non-null  float64\n",
      "dtypes: float64(9), object(4)\n",
      "memory usage: 2.7+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24944 entries, 0 to 24943\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   IDpol        24944 non-null  float64\n",
      " 1   ClaimNb      24944 non-null  float64\n",
      " 2   Exposure     24944 non-null  float64\n",
      " 3   Area         24944 non-null  object \n",
      " 4   VehPower     24944 non-null  float64\n",
      " 5   VehAge       24944 non-null  float64\n",
      " 6   DrivAge      24944 non-null  float64\n",
      " 7   BonusMalus   24944 non-null  float64\n",
      " 8   VehBrand     24944 non-null  object \n",
      " 9   VehGas       24944 non-null  object \n",
      " 10  Density      24944 non-null  float64\n",
      " 11  Region       24944 non-null  object \n",
      " 12  PurePremium  24944 non-null  float64\n",
      "dtypes: float64(9), object(4)\n",
      "memory usage: 2.7+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24944 entries, 0 to 24943\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Area         24944 non-null  object \n",
      " 1   VehPower     24944 non-null  float64\n",
      " 2   VehAge       24944 non-null  float64\n",
      " 3   DrivAge      24944 non-null  float64\n",
      " 4   BonusMalus   24944 non-null  float64\n",
      " 5   VehBrand     24944 non-null  object \n",
      " 6   VehGas       24944 non-null  object \n",
      " 7   Density      24944 non-null  float64\n",
      " 8   Region       24944 non-null  object \n",
      " 9   PurePremium  24944 non-null  float64\n",
      " 10  Frequency    24944 non-null  float64\n",
      "dtypes: float64(7), object(4)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_sev_updated = df_sev.groupby('IDpol')['PurePremium'].sum().reset_index()\n",
    "# 24950 rows Ã— 2 columns\n",
    "\n",
    "# Perform an inner Join to merge the two dataframes\n",
    "inner_join_df = pd.merge(df_freq, df_sev_updated, on='IDpol', how='inner')\n",
    "\n",
    "combined_df = inner_join_df.copy()\n",
    "\n",
    "print(combined_df.info())\n",
    "combined_df.head()\n",
    "combined_df.info()\n",
    "combined_df.describe()\n",
    "\n",
    "\n",
    "# Create the new column \"PurePremium\" by dividing \"PurePremium\" by \"Exposure\"\n",
    "combined_df['PurePremium'] = combined_df['PurePremium'] / combined_df['Exposure']\n",
    "\n",
    "# Create the new column \"Frequency\" by dividing \"ClaimNb\" by \"Exposure\"\n",
    "combined_df['Frequency'] = combined_df['ClaimNb'] / combined_df['Exposure']\n",
    "\n",
    "# Remove the columns \n",
    "combined_df.pop('IDpol')\n",
    "combined_df.pop('ClaimNb')\n",
    "combined_df.pop('Exposure')\n",
    "combined_df.info()\n",
    "\n",
    "\n",
    "y_premium_column = combined_df.pop('PurePremium')\n",
    "combined_df['PurePremium'] = y_premium_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24899 entries, 0 to 24943\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Area         24899 non-null  object \n",
      " 1   VehPower     24899 non-null  float64\n",
      " 2   VehAge       24899 non-null  float64\n",
      " 3   DrivAge      24899 non-null  float64\n",
      " 4   BonusMalus   24899 non-null  float64\n",
      " 5   VehBrand     24899 non-null  object \n",
      " 6   VehGas       24899 non-null  object \n",
      " 7   Density      24899 non-null  float64\n",
      " 8   Region       24899 non-null  object \n",
      " 9   Frequency    24899 non-null  float64\n",
      " 10  PurePremium  24899 non-null  float64\n",
      "dtypes: float64(7), object(4)\n",
      "memory usage: 2.3+ MB\n",
      "           VehPower        VehAge       DrivAge    BonusMalus       Density  \\\n",
      "count  24899.000000  24899.000000  24899.000000  24899.000000  24899.000000   \n",
      "mean       6.469577      7.384554     45.150649     64.917708   1983.996546   \n",
      "std        2.013247      5.173428     14.651704     19.856510   4119.451746   \n",
      "min        4.000000      0.000000     18.000000     50.000000      2.000000   \n",
      "25%        5.000000      3.000000     34.000000     50.000000    111.000000   \n",
      "50%        6.000000      7.000000     45.000000     55.000000    493.000000   \n",
      "75%        7.000000     11.000000     54.000000     76.000000   2120.000000   \n",
      "max       15.000000     99.000000     99.000000    228.000000  27000.000000   \n",
      "\n",
      "          Frequency   PurePremium  \n",
      "count  24899.000000  24899.000000  \n",
      "mean       3.108355      7.441633  \n",
      "std        9.106552      1.400259  \n",
      "min        0.500000      0.000000  \n",
      "25%        1.000000      7.028201  \n",
      "50%        1.351351      7.315990  \n",
      "75%        2.409639      8.115056  \n",
      "max      365.000000     13.275198  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the Z-score for 'PurePremium' column\n",
    "z_scores = np.abs((combined_df['PurePremium'] - combined_df['PurePremium'].mean()) / combined_df['PurePremium'].std())\n",
    "\n",
    "# Define the threshold for outliers (e.g., Z-score greater than 3)\n",
    "threshold = 3\n",
    "\n",
    "# Find the indices of outliers\n",
    "outlier_indices = np.where(z_scores > threshold)[0]\n",
    "\n",
    "# Create a DataFrame containing only the outliers\n",
    "df_outliers = combined_df.iloc[outlier_indices]\n",
    "\n",
    "df_scaled_cleaned = combined_df.drop(outlier_indices)\n",
    "\n",
    "combined_df = df_scaled_cleaned.copy()\n",
    "combined_df.info()\n",
    "\n",
    "# Log transform the 'PurePremium' column\n",
    "combined_df['PurePremium'] = np.log(combined_df['PurePremium'])\n",
    "\n",
    "print(combined_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24899 entries, 0 to 24943\n",
      "Data columns (total 44 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   VehPower        24899 non-null  float64\n",
      " 1   VehAge          24899 non-null  float64\n",
      " 2   DrivAge         24899 non-null  float64\n",
      " 3   BonusMalus      24899 non-null  float64\n",
      " 4   Density         24899 non-null  float64\n",
      " 5   Frequency       24899 non-null  float64\n",
      " 6   Area_'B'        24899 non-null  uint8  \n",
      " 7   Area_'C'        24899 non-null  uint8  \n",
      " 8   Area_'D'        24899 non-null  uint8  \n",
      " 9   Area_'E'        24899 non-null  uint8  \n",
      " 10  Area_'F'        24899 non-null  uint8  \n",
      " 11  VehBrand_'B10'  24899 non-null  uint8  \n",
      " 12  VehBrand_'B11'  24899 non-null  uint8  \n",
      " 13  VehBrand_'B12'  24899 non-null  uint8  \n",
      " 14  VehBrand_'B13'  24899 non-null  uint8  \n",
      " 15  VehBrand_'B14'  24899 non-null  uint8  \n",
      " 16  VehBrand_'B2'   24899 non-null  uint8  \n",
      " 17  VehBrand_'B3'   24899 non-null  uint8  \n",
      " 18  VehBrand_'B4'   24899 non-null  uint8  \n",
      " 19  VehBrand_'B5'   24899 non-null  uint8  \n",
      " 20  VehBrand_'B6'   24899 non-null  uint8  \n",
      " 21  VehGas_Regular  24899 non-null  uint8  \n",
      " 22  Region_'R21'    24899 non-null  uint8  \n",
      " 23  Region_'R22'    24899 non-null  uint8  \n",
      " 24  Region_'R23'    24899 non-null  uint8  \n",
      " 25  Region_'R24'    24899 non-null  uint8  \n",
      " 26  Region_'R25'    24899 non-null  uint8  \n",
      " 27  Region_'R26'    24899 non-null  uint8  \n",
      " 28  Region_'R31'    24899 non-null  uint8  \n",
      " 29  Region_'R41'    24899 non-null  uint8  \n",
      " 30  Region_'R42'    24899 non-null  uint8  \n",
      " 31  Region_'R43'    24899 non-null  uint8  \n",
      " 32  Region_'R52'    24899 non-null  uint8  \n",
      " 33  Region_'R53'    24899 non-null  uint8  \n",
      " 34  Region_'R54'    24899 non-null  uint8  \n",
      " 35  Region_'R72'    24899 non-null  uint8  \n",
      " 36  Region_'R73'    24899 non-null  uint8  \n",
      " 37  Region_'R74'    24899 non-null  uint8  \n",
      " 38  Region_'R82'    24899 non-null  uint8  \n",
      " 39  Region_'R83'    24899 non-null  uint8  \n",
      " 40  Region_'R91'    24899 non-null  uint8  \n",
      " 41  Region_'R93'    24899 non-null  uint8  \n",
      " 42  Region_'R94'    24899 non-null  uint8  \n",
      " 43  PurePremium     24899 non-null  float64\n",
      "dtypes: float64(7), uint8(37)\n",
      "memory usage: 2.4 MB\n",
      "Missing values:\n",
      " VehPower          0\n",
      "VehAge            0\n",
      "DrivAge           0\n",
      "BonusMalus        0\n",
      "Density           0\n",
      "Frequency         0\n",
      "Area_'B'          0\n",
      "Area_'C'          0\n",
      "Area_'D'          0\n",
      "Area_'E'          0\n",
      "Area_'F'          0\n",
      "VehBrand_'B10'    0\n",
      "VehBrand_'B11'    0\n",
      "VehBrand_'B12'    0\n",
      "VehBrand_'B13'    0\n",
      "VehBrand_'B14'    0\n",
      "VehBrand_'B2'     0\n",
      "VehBrand_'B3'     0\n",
      "VehBrand_'B4'     0\n",
      "VehBrand_'B5'     0\n",
      "VehBrand_'B6'     0\n",
      "VehGas_Regular    0\n",
      "Region_'R21'      0\n",
      "Region_'R22'      0\n",
      "Region_'R23'      0\n",
      "Region_'R24'      0\n",
      "Region_'R25'      0\n",
      "Region_'R26'      0\n",
      "Region_'R31'      0\n",
      "Region_'R41'      0\n",
      "Region_'R42'      0\n",
      "Region_'R43'      0\n",
      "Region_'R52'      0\n",
      "Region_'R53'      0\n",
      "Region_'R54'      0\n",
      "Region_'R72'      0\n",
      "Region_'R73'      0\n",
      "Region_'R74'      0\n",
      "Region_'R82'      0\n",
      "Region_'R83'      0\n",
      "Region_'R91'      0\n",
      "Region_'R93'      0\n",
      "Region_'R94'      0\n",
      "PurePremium       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Features to be Normalised\n",
    "numerical_features = ['Frequency', 'VehPower', 'VehAge', 'DrivAge', 'BonusMalus', 'Density']\n",
    "\n",
    "# Features to be encoded\n",
    "columns_to_encode = ['Area', 'VehBrand', 'VehGas', 'Region']\n",
    "\n",
    "# Copy the DataFrame to avoid modifying the original\n",
    "data = combined_df.copy()\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values\n",
    "    ('scaler', StandardScaler())                     # Scale the features\n",
    "])\n",
    "\n",
    "# Apply the pipeline to numerical features\n",
    "data[numerical_features] = pipeline.fit_transform(data[numerical_features])\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Save the scaler used during training\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(pipeline.named_steps['scaler'], file)\n",
    "\n",
    "# Apply one-hot encoding\n",
    "data = pd.get_dummies(data, columns=columns_to_encode, drop_first=True)\n",
    "\n",
    "\n",
    "y_premium_column = data.pop('PurePremium')\n",
    "data['PurePremium'] = y_premium_column\n",
    "\n",
    "df = data.copy()\n",
    "df.info()\n",
    "df.describe()\n",
    "print(\"Missing values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Outliers from numerical features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame containing the data\n",
    "columns_of_interest = ['Frequency', 'VehPower', 'VehAge', 'DrivAge', 'BonusMalus', 'Density']\n",
    "\n",
    "# Step 2: Z-Score Method\n",
    "from scipy import stats\n",
    "\n",
    "z_scores = np.abs(stats.zscore(df[columns_of_interest]))\n",
    "threshold = 3\n",
    "outliers_z = np.where(z_scores > threshold)\n",
    "\n",
    "# Step 3: IQR Method\n",
    "Q1 = df[columns_of_interest].quantile(0.25)\n",
    "Q3 = df[columns_of_interest].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "outliers_iqr = ((df[columns_of_interest] < lower_bound) | (df[columns_of_interest] > upper_bound)).any(axis=1)\n",
    "\n",
    "# Combine results\n",
    "outliers = set(outliers_z[0]) | set(outliers_iqr.index[outliers_iqr])\n",
    "\n",
    "# Remove outliers identified by IQR method\n",
    "df_no_outliers_iqr = df[~outliers_iqr]\n",
    "df = df_no_outliers_iqr.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Hyperparameters: {'subsample': 0.9, 'n_estimators': 30, 'max_depth': 3, 'learning_rate': 0.2, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error, explained_variance_score\n",
    "\n",
    "# Assuming X contains features and y contains the target variable 'PurePremium'\n",
    "X = df.drop(columns=['PurePremium'])\n",
    "y = df['PurePremium']\n",
    "\n",
    "# Splitting the data into training, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# Define hyperparameters for XGBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 20, 30, 40],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9],\n",
    "}\n",
    "\n",
    "# Initialize XGBoost regressor\n",
    "xgb_reg = XGBRegressor(random_state=0)\n",
    "\n",
    "# Perform random search with cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=xgb_reg, param_distributions=param_grid, \n",
    "                                   n_iter=50, scoring='neg_mean_squared_error', cv=5, \n",
    "                                   verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator and its hyperparameters\n",
    "best_estimator = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "import pickle\n",
    "# Save the trained model to a pickle file\n",
    "with open('xgb_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_estimator, file)\n",
    "\n",
    "# Predictions on the validation set\n",
    "y_pred_val = np.exp(best_estimator.predict(X_val))  # Perform inverse log transformation\n",
    "\n",
    "# Calculate evaluation metrics for validation set\n",
    "mae_val = mean_absolute_error(y_val, y_pred_val)\n",
    "mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "rmse_val = np.sqrt(mse_val)\n",
    "r2_val = r2_score(y_val, y_pred_val)\n",
    "medae_val = median_absolute_error(y_val, y_pred_val)\n",
    "explained_var_val = explained_variance_score(y_val, y_pred_val)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred_test = np.exp(best_estimator.predict(X_test))  # Perform inverse log transformation\n",
    "\n",
    "# Calculate evaluation metrics for test set\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "medae_test = median_absolute_error(y_test, y_pred_test)\n",
    "explained_var_test = explained_variance_score(y_test, y_pred_test)\n",
    "\n",
    "# Predictions on the training set\n",
    "y_pred_train = np.exp(best_estimator.predict(X_train))  # Perform inverse log transformation\n",
    "\n",
    "# Calculate evaluation metrics for training set\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "medae_train = median_absolute_error(y_train, y_pred_train)\n",
    "explained_var_train = explained_variance_score(y_train, y_pred_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Premium for Input Data as follows: Frequency calculated separately for ClaimNb = 1\tExposure = 0.17\n",
    "#### 'Frequency': [5.88],\n",
    "#### 'Area': ['C'],\n",
    "####  'VehPower': [5],\n",
    "####  'VehAge': [5],\n",
    "####  'DrivAge': [41],\n",
    "####  'BonusMalus': [68],\n",
    "####  'VehBrand': ['B4'],\n",
    "####  'VehGas': ['Diesel'],\n",
    "####  'Density': [160],\n",
    "####  'Region': ['R23']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted PurePremium: [5802.4556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load the trained model from the pickle file\n",
    "with open('xgb_model.pkl', 'rb') as file:\n",
    "    trained_model = pickle.load(file)\n",
    "\n",
    "# Load the trained model from the pickle file\n",
    "with open('xgb_model.pkl', 'rb') as file:\n",
    "    trained_model = pickle.load(file)\n",
    "\n",
    "# Load the scaler used during training\n",
    "with open('scaler.pkl', 'rb') as file:\n",
    "    scaler = pickle.load(file)\n",
    "\n",
    "# Define the new data\n",
    "new_data = pd.DataFrame({\n",
    "    'Frequency': [5.88],\n",
    "    'Area': ['C'],\n",
    "    'VehPower': [5],\n",
    "    'VehAge': [5],\n",
    "    'DrivAge': [41],\n",
    "    'BonusMalus': [68],\n",
    "    'VehBrand': ['B4'],\n",
    "    'VehGas': ['Diesel'],\n",
    "    'Density': [160],\n",
    "    'Region': ['R23']\n",
    "})\n",
    "\n",
    "# Encode categorical variables\n",
    "new_data = pd.get_dummies(new_data, columns=['Area', 'VehBrand', 'VehGas', 'Region'])\n",
    "\n",
    "# Scale numerical features using the same StandardScaler instance from training\n",
    "numerical_features = ['Frequency', 'VehPower', 'VehAge', 'DrivAge', 'BonusMalus', 'Density']\n",
    "new_data[numerical_features] = scaler.transform(new_data[numerical_features])\n",
    "\n",
    "# Rearrange columns to match the order of the columns in the training data\n",
    "new_data = new_data.reindex(columns=df.columns[:-1], fill_value=0)\n",
    "\n",
    "# Predict PurePremium using the trained model\n",
    "predicted_pure_premium = trained_model.predict(new_data)\n",
    "\n",
    "# Perform inverse log transformation\n",
    "predicted_pure_premium = np.exp(predicted_pure_premium)\n",
    "\n",
    "# Print the predicted PurePremium\n",
    "print(\"\\nPredicted PurePremium:\", predicted_pure_premium)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted Premium to be Paid: 5802.4556"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
